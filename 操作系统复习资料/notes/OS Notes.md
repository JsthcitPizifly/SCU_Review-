# 操作系统

@toc

* * *

# 人们熟悉的操作系统

1. windows 
2. Android
3. iOS
4. macOS
5. Linux
6. Unix

* * *

## 操作系统的概念（定义）

- 1. 负责管理协调硬件、软件等计算机资源的工作
- 2. 为上层的应用程序、用户提供简单易用的服务
- 3. 操作系统是最基本的系统软件，不是硬件
- 4. [进程](#进程)是一个程序的执行过程。执行前需要将该程序放到内存中，才能被CPU处理

* * *

## 操作系统的功能和目标——作为用户和计算机之间的接口

1. 操作系统作为系统资源的管理者，他需要提供什么功能？
   **①文件管理**
   **②内存管理**
   **③处理机(CPU)管理**
   **④设备管理(如：摄像头)**
2. 操作系统作为用户和计算机硬件之间的接口，要为其上层提供什么功能？
   ①命令接口 (联机命令接口, 脱机命令接口)
   联机命令接口=交互式命令接口：用户说一句，系统做一句
   脱机命令接口=批处理命令接口：用户说一堆，系统做一堆
   ②程序接口
   ③图形用户界面（GUI）
3. 操作系统作为最接近硬件的层次，需要在纯硬件的基础上实现什么功能？
   ①实现对硬件机器的拓展

* * *

## 操作系统的四个特征

1. [并发](#并发)
2. [共享](#共享)
3. [虚拟](#虚拟)
4. [异步](#异步)

### 并发

 **指两个或者多个事件在同一时间间隔内发生。这些事件在宏观上是同时发生的，但在微观上是交替发生的。**

- 并发性指的是计算机系统中同时存在着多个运行着的程序
- 一个单核处理器(CPU)同一时刻只能执行一个程序，因此操作系统会负责协调多个程序交替执行(微观上是交替执行的，宏观上是同时执行的)
- 与并行不同，并行指的是两个或者多个事件在同一时刻同时发生。

### 共享

 **共享即资源共享，指系统中的资源可供内存中多个并发执行的进程共同使用**

- 互斥共享：系统中的某些资源，在一个时间段内只能允许一个[进程](os-notes)访问对资源访问
  如：使用QQ和微信进行视频，同一时间段内摄像头只能分配给一个进程使用。
- 同时共享：指一个时间段内，允许多个进程同时对资源进行访问
  如：使用QQ发送文件A，微信发送文件B。宏观上看，两个进程同时在读取并发送文件，两个进程都在访问硬盘资源。微观上看，两个进程在交替访问硬盘。
  - 同时是宏观上的同时，微观上还是进程交替的访问

### 并发和共享的关系

使用QQ发送文件A，同时使用微信发送文件B

1. 两个进程在并发执行
2. 需要共享地访问硬盘资源

如果失去[并发性](#并发)，则系统只有一个程序在运行，共享性失去其意义。
如果失去[共享性](#共享)，则两个进程不能同时访问硬盘资源，则无法实现同时发送文件，也就无法并发。
**并发性和共享性互为存在条件。**

### 虚拟

 **指把一个物理上的实体变为若干个逻辑上的对应物。物理实体是实际存在的，而逻辑上的对应物是用户感受到的。**

- 虚拟内存(空分复用技术)--（过后补充）
- 例子：在单核CPU下可以运行多个进程，运用了虚拟处理机技术。（时分复用技术）

### 异步

**指多到程序环境下，允许多个进程并发执行，但由于资源有限，进程的执行不是一贯到底的，而是走走停停，以不可预知的速度向前推进**

* * *

## 内核

内核是操作系统最基本的部分。它是为众多应用[程序](https://baike.baidu.com/item/%E7%A8%8B%E5%BA%8F)提供对计算机[硬件](https://baike.baidu.com/item/%E7%A1%AC%E4%BB%B6)的安全访问的一部分[软件](https://baike.baidu.com/item/%E8%BD%AF%E4%BB%B6/12053)，这种访问是有限的，并且内核决定一个程序在什么时候对某部分硬件操作多长时间。内核的分类可分为[单内核](https://baike.baidu.com/item/%E5%8D%95%E5%86%85%E6%A0%B8/4234453)和双内核以及[微内核](https://baike.baidu.com/item/%E5%BE%AE%E5%86%85%E6%A0%B8/3856137)。严格地说，内核并不是[计算机系统](https://baike.baidu.com/item/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/7210959)中必要的组成部分。

- 原子性：指不可中途停止。

* * *

# 进程和线程

## 进程

1. 进程的定义
   系统为每个运行的程序配置一个数据结构，成为**进程控制块(process control block）**，用来描述进程的各种信息（如代码存放的位置信息）

- **PCB、程序段、数据段三部分构成了进程实体（进程映像）**
  - 程序段：储存着程序代码
  - 数据段：程序运行时使用，产生运算数据。如全局变量，局部变量，宏定义的常量。
  - PCB：操作系统用于管理进程所需各种信息。
    - 1. 进程描述信息：进程标识符PID，用户标识符UID
    - 2. 进程控制和管理信息：进程当前状态，进程优先级

我们把进程实体简称为进程，创建一个进程，实质上就是创建进程实体中的PCB
**PCB是进程存在的唯一标志**

- 进程是程序的一次执行过程
- 进程是一个程序及其数据在处理机顺序执行时发生的活动
- 进程是具有独立功能的程序在数据集合上运行的过程
- **进程**是进程实体的运行过程，是系统进行**资源分配**和**调度**的一个独立单位
- 进程实体是静态的，进程是动态的

### 进程的组织

1. 链接方式
   ①按照进程状态将PCB分为多个**队列**
   ②操作系统持有指向各个队列的指针
2. 索引方式
   ①根据进程状态不同，建立几张**索引表**
   ②操作系统持有指向索引表的指针

### 进程的特征

- **动态性**
  进程是程序的一次执行过程，是动态地产生，变化和消亡的
- **并发性**
  内存中有多个进程实体，各进程可并发执行
- **独立性**
  进程是能独立运行，独立获取资源，独立接受调度的基本单位
  **进程是资源分配和接受调度的基本单位**
- **异步性**
  各进程按各自独立的，不可预知的速度向前推进
- **结构性**
  每个进程都会配置一个PCB。结构上看，进程由程序段，数据段和PCB构成

### 进程的状态和转换

#### 状态

- **运行状态**
  占用CPU资源，在CPU上运行
- **就绪状态**
  已具备运行状态，但由于没有空闲的CPU，暂时不能运行
- **阻塞状态**
  因等待某一事件而暂时不能运行，如等待系统分配打印机
- **创建状态**
  在新建进程时，在运行之前，需要进行一定处理，如初始化PCB等
- **中止状态**
  进程运行结束，或者是由于BUG无法继续进行下去，需要撤销进程，对进程资源进行回收

#### 转换

- 就绪态-->运行态
  进程被调度
- 运行态-->就绪态
  时间片到，或CPU被高优先级进程抢占
- 运行态-->阻塞态（主动行为）
  进程用系统调度的方式申请某种系统资源
- 阻塞态-->就绪态（被动行为）
  申请的资源被分配，或者等待的事件发生 

## 线程

- 每个进程中可能包含多个线程，提高系统的并发度
- **线程是程序执行流的最小单位**
- **线程**是一个**基本的CPU执行单元**，也是**程序执行流的最小单位**
- 可以使得一个进程内进行各种各样的任务
- 进程只作为除CPU之外的系统资源的分配单元，系统资源是分配给进程而不是线程
- 引入线程后，进程只作为资源分配的基本单位，线程是调度的基本单位
- 切换同一进程内的不同线程，则不需要切换进程环境，减少系统开销
- 线程有**就绪、阻塞、运行**三种基本状态

#### 线程的实现方式

1. 用户级线程 （User-Level Theread，ULT）
   用户级线程由应用程序通过线程库实现
   对用户不透明，对操作系统透明
   用户级线程是从用户的视角看到的线程
2. 内核级线程（Kernel-Level Thread，KLT）
   内核级线程的管理工作由操作系统内核完成。
   内核级线程就是从操作系统的内核视角看到的线程

**操作系统只看得见内核级线程，因此只有内核级线程才是CPU分配的单位**

#### 多线程模型

1. 多对一模型
   多个用户级线程映射到一个内核级线程。
   优点：开销小，效率高
   缺点：并发度不高，一个用户级线程被阻塞，整个进程就会被阻塞
2. 一对一模型
   一个用户级线程对应一个内核级线程
   优点：并发度高
   缺点：开销大，效率低
3. 多对多模型
   n用户级线程映射到m内核级线程上
   优点：集二者所长

* * *

## 进程同步和进程互斥

### 进程同步

怎么解决进程异步的问题，同步又称为直接制约关系，多个进程需要相互协调完成某一种工作，必须按照一定顺序执行，即为进程同步

### 进程互斥

进程的并发需要共享系统资源的，互斥指的是一个时间段内只允许一个进程访问的系统资源

### 临界资源

我们把一个时间段内只允许一个进程使用的资源称为临界资源。对于临界资源的访问需要互斥的进程，当一个进程需要访问临界资源时，另一个需要访问该临界资源的进程必须等待，当第一个访问临界资源的进程结束后，第二个进程才可访问。

对于临界资源的互斥访问，在逻辑下分为以下四个部分

```cpp
do {
  entry section; //1. 进入区 
  critical section;//2. 临界区 
  exit section;//3. 退出区 
  remainder section;//4. 剩余区
}while(true);
```

1. 负责检查是否可以进入临界区，若可进入就上锁，其他的进程就不可以访问临界资源
2. 实际访问临界资源的代码
3. 解锁
4. 做其他处理

**①**空闲让进。临界区空闲时，可以允许一个请求进入临界区的进程立即进入临界区
**②**忙则等待。当已有进程进入临界区时，其他视图进入临界区的进程必须等待
**③**有限等待。如果一个进程暂时无法进入临界区，必须保证这个进程在有限时间进入临界区
**④**让权等待。当进程不能进入临界区时，应立即释放处理机，防止忙等待（无法推进却一直占领处理机）

* * *

## 信号量机制

### 信号量

信号量其实就是一个变量（可以是一个整数，也可以是更复杂的记录型变量），可以用一个信号量来表示系统中某种资源的数量。
用原子操作来实现信号量机制，其执行只能一气呵成，不可被中断。
一对原子操作：wait(S)和signal(S) ，信号量S其实就是函数调用传入的一个参数，wait、signal常简称为P、V操作，wait(S)又叫P(S)；signal(S)又叫V(S)

#### 整型信号量

用一个整数型的变量作为信号量，用来表示系统中某种资源的数量

```cpp
int S = 1; //初始化信号量，用来表示系统中某种资源的数量。

void wait(int S) {
  while (S <= 0);
  S = S - 1;
}

void signal (int S) {
  S = S + 1;
}

//进程P0
...
wait(S);
//使用资源
signal(S);
```

“检查”和“上锁”一气呵成，避免了并发、异步导致的问题。
无法解决忙等问题

#### 记录型信号量

```cpp
struct semaphore{
  int value;            //剩余的资源数
  struct process *L;    //指向等待队列的指针
}

void wait(semaphore S)    //P操作
{
  S.value--;
  //如果剩余资源数不够，使用block让进程从运行态进入阻塞态
  if (S.value < 0) 
    block(S.L);
}

void signale(semaphore S) //V操作
{
  S.value++;
  //释放资源后，若还有别的进程在等待这种资源
  //则唤醒等待队列的一个进程，使其从阻塞态进入就绪态
  if (S.value <= 0) 
    wakeup(S.L);
}
```

- 信号量为整数，表示还剩多少数目的资源可以被调用
- 信号量为负数，表示还有多少进程需要使用该资源

### 用信号量机制实现进程同步

 进程同步： 要让各并发进程按要求有序地推进

1. 分析什么地方需要实现同步关系，保证操作需要一前一后的执行
2. 设置同步信号量S，初始化为0
3. 在前操作之后执行V(S)
4. 在后操作之前执行P(S)
   相当于，A操作执行之后才释放系统资源给B操作用，如果A操作没有执行，则没有空闲的系统资源，则B操作不能进行，如果B操作先进行，发现没有可用的系统资源，则自发进入阻塞态等待A操作执行并释放系统资源调用B操作

```cpp
semaphore S = 0;
P1()
{
  code1;
  code2;
  V(S);    //V是signal操作 P是wait操作
  code2;
}

P2() 
{
  P(S);
  code4;
  code5;
  code6;
}
```

### 生产者消费者问题

系统中有一组生产者进程和一组消费者进程，生产者进程每次生产一个产品放入缓冲区，消费者进程每次从缓冲区中取出一个产品并使用（产品可以理解为某种数据）
生产者、消费者共享一个初始为空，大小为n的缓冲区
只有缓冲区没满时，生产者才能把产品放入缓冲区，否则必须等待
![生产者消费者1](%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E8%B4%B9%E8%80%851.jpg)
只有缓冲区不为空，消费者才能从中取出产品，否则必须等待
![生产者消费者2](%E7%94%9F%E4%BA%A7%E8%80%85%E6%B6%88%E8%B4%B9%E8%80%852.jpg)

缓冲区是临界资源，必须被互斥的访问
信号量机制可实现互斥和同步、对一类系统资源的申请和释放

- 互斥
  设置初始值为1的互斥信号量
- 同步
  设置初始值为0的同步信号量（实现“一前一后”）
- 申请和释放资源
  设置一个信号量，初始值为资源的数量，若无空闲资源，则申请资源的进程需要等待别的进程释放资源后才能继续往下执行

```cpp
semaphore mutex = 1; //互斥信号量，实现对缓冲区的互斥访问
semaphore empty = n; //同步信号量，表示空闲缓冲区的数量
semaphore full = 0; //同步信号量，表示产品的数量，也即非空缓冲区的数量

producer ()
{
  while (1){
    生产一个产品;
    P(empty); //消耗一个空闲缓冲区
    P(mutex);
    把产品放入缓冲区
    V(mutex);
    V(full);
  }
}

consumer()
{
  while (1) {
    P(full);  //消耗一个非空缓冲区
    P(mutex);
    从缓冲区取走一个产品
    V(mutex);
    V(empty); //增加一个空闲缓冲区
    使用产品;
  }
}
```

**实现互斥操作要在同步操作之后，不然会发生死锁**

## 管程

信号量机制存在的问题：编写程序困难，易出错

#### 定义

- 局部于管程的共享数据结构说明；
- 对该数据结构进行操作的一组过程（方法）；
- 对局部于管程的共享数据设置初始值的语句；
- 管程有一个名字

#### 基本特征

- 局部于管程的数据只能被局部于管程的过程所访问
- 一个进程只有通过调用管程内的进程才能进入管程共享访问数据
- 每次仅允许一个进程在管程内执行某个内部过程 

```cpp
monitor ProducerCounsumer
  condition full, empty;  //条件变量用来实现同步
  int count = 0;  //缓冲区的产品数
  void insert (Item item){
    if (count == N)
      wait(full);
    count ++;
    insert_item(item);
    if (count == 1)
      signal(empty);
  }

  Item remove() {
    if (count == 0)
      wait (empty);
    count --;
    if (count = N-1)
      signal(full);
    return remove_item();
  }
end monitor;

producer () {
  while(1) {
  item = 生产一个产品;
  ProdecerCounsumer.insert(item);
  }
}

consumer () {
  while(1) {
    item = ProducerConsumer.remove ();
    消费产品;
  }
}
```

**由编译器负责实现各进程互斥地进入管程中的过程**
**管程中设置条件变量实现等待和唤醒操作，解决同步问题**

* * *

### 死锁

#### 死锁的概念

指各个进程互相等待对方的资源，导致各进程阻塞，无法向前推进

#### 什么会导致死锁

1. 对系统资源的竞争，各进程对不可剥夺的资源的竞争可能引起死锁，对可剥夺的资源（CPU）的竞争是不会引起死锁
2. 进程推进非法，请求和释放资源的顺序不当。
3. 信号量的使用不当，如生产者消费者问题中实现互斥的P在实现同步的P之前

#### 产生死锁的必要条件：

- **互斥条件**：对必须互斥使用的资源的争抢才会导致死锁
- **不可剥夺条件**：进程保持的资源只能主动释放，不可强行剥夺
- **请求和保持条件**： 保持着某些资源不放的同时，请求别的资源
- **循环等待条件**：存在一种进程资源的循环等待链

总之，对不可剥夺的资源的不合理分配，可能会导致死锁。

#### 死锁的处理策略

1. 预防死锁。破坏死锁产生的四个必要条件中的一个或几个。
2. 避免死锁。用某种方法防止系统进入不安全状态，从而避免思索（银行家算法）
3. 死锁的检测和接触。允许死锁发生，不过操作系统会检测出死锁的发生，然后采取某种措施解除死锁。

#### 避免死锁和银行家算法

* * *

# 内存管理

## 什么是内存

内存是用于存放数据的硬件。程序执行前**需要先放到内存中才能被CPU处理。**

内存地址从0开始，每个内存地址对应一个存储单元

- 如果计算机按字节编址，则每个储存单元的大小为一个字节，1B，8位
- 如果按16位字长编址，则每个储存单元大小为一个字，每个字的大小为16个二进制数

* * *

## 内存空间的分配与回收

连续分配管理方式

- 单一连续分配
- 固定分区分配
- 动态分区分配

### 内部碎片

分配给某进程的内存区域中，存在着某些没有用上的区域，称为内部碎片。

### 外部碎片

指内存中某些空闲分区由于太小而难以利用，称为外部碎片

### 单一连续分配

在单一连续分配方式中没存被分为系统区和用户区，系统区通常位于内存的低地址部分，用于存放操作系统相关数据，用户区用于存放用户进程相关数据。

内存中**只能有一个用户程序**，用户程序独占真个用户区空间。

优点：实现简单，无外部碎片。
缺点：只能用户单用户、单人舞的操作系统，有内部碎片，存储器利用率极低

* * *

## 固定分区分配方式

将整个用户空间划分为若干个固定大小的分区，在每个分区中只装入一道作业

### 固定分区分配

- 分区大小相等
- 分区大小不等

### 分区大小相等

1. 缺乏灵活性
2. 适用于用一台计算机 控制多个相同对象的场合
   钢铁厂里有n个大小相等的炼钢炉，就可以把内存分为n个大小相等的区域

### 分区大小不等

1. 增加灵活性
2. 可以满足不同大小的进程需求

操作系统需要将建立一个数据结构——分区说明表，来实现各个分区的分配与回收。每个表对应一个分区，通常按分区大小排列。每个表项包括对应分区的大小、起始地址、状态等。

| 分区号 | 大小(MB) | 起始地址 | 状态  |
| --- | ------ | ---- | --- |
| 1   | 2      | 8    | 未分配 |
| 2   | 2      | 8    | 未分配 |
| 3   | 4      | 12   | 已分配 |

当某用户程序要装入内存时，由操作系统内核程序根据用户程序大小检索该表，从中找到一个能满足大小、未分配的分区，将其分配给该程序，然后将状态修改为已分配

#### 优点

1. 实现简单
2. 无[外部碎片](#外部碎片)

#### 缺点

1. 一个用户程序太大的时候，可能所有分区都不满足要求
2. 会产生[内部碎片](#内部碎片)，内存利用率低

### 动态分区分配

动态分区分配又称为可变分区分配。不会提前划分内存分区，而是在进程装入内存时根据进程的大小动态地建立分区。

#### 用什么样的数据结构记录内存使用情况？

##### 空闲分区表

   每个空闲分区对应一个表项，表项中包含分区号，分区大小，分区起始地址等信息

##### 空闲分区链

   每个分区的起始部分和末尾部分分别设置前项指针和后项指针。起始部分处还可以记录分区大小等信息。

#### 当有很多分区满足，用哪一个？

把一个新作业装入内存时，须按照一定的**动态分区分配算法**，从空闲分区表中选出一个分区分配给该作业

#### 如何进行分区的分配与回收？

以空闲分区表为例

1. 进程大小小于分区大小
   采用某种算法，将进程分给某个分区，如果进程大小小于分区大小，则直接在空闲分区表上更改分区大小即可
2. 进程大小等于分区大小
   空闲分区数量减一，在空闲分区表项删除

#### 如何进行分配和回收？

1. 情况一：回收区后面有一个相邻的空闲分区
   两个相邻的空闲分区合二为一
2. 情况二：回收区前面有一个相邻的空闲分区
   两个相邻的空闲分区合二为一
3. 情况三：回收区的前、后各有一个空闲分区
   三个相邻的空闲分区合二为一
4. 回收区前后都没有空闲分区
   在空闲分区表中增加一个表项

#### 总结

1. 动态内存分配没有内部碎片，但是有外部碎片。
2. 如果内存中空闲空间的总和本来可以满足某进程的要求，但由于进程需要的是一整块连续的内存空间，因此这些**碎片**不能满足进程的需求
3. 可以通过 **紧凑（Compaction）** 技术来解决外部碎片（压缩？）

![总结](%E8%BF%9E%E7%BB%AD%E5%88%86%E9%85%8D%E7%AE%A1%E7%90%86.png)

### 动态分区分配算法

- [首次适应算法（First Fit)](#首次适应算法-first-fit)
- [最佳适应算法（Best Fit）](#最佳适应算法-best-fit)
- [最坏时应算法（Worst Fit）](#最坏时应算法-worst-fit)
- [邻近适应算法（Next Fit）](#邻近适应算法-next-fit)

* * *

#### 首次适应算法(First Fit)

##### 算法思想

每次从低地址部分开始查找，找到第一个满足大小的空闲分区

##### 如何实现

空闲分区以地址递增的次序排列。每次分配内存时顺序查找[空闲分区链](#空闲分区链)或者[空闲分区表](#空闲分区表)，找到大小能满足要求的第一个空闲分区

* * *

#### 最佳适应算法(Best Fit)

##### 算法思想

由于动态分区分配是一种连续分配的方式，为各个进程分配的空间必须是连续的一整片区域。因此为了保证当“大进程”到来时能有连续的大片区域，可以尽可能多地留下大片的空闲区，即，优先使用更小的空闲区。

##### 如何实现

空闲分区按容量递增次序链接。每次分配内存时顺序查找[空闲分区链](#空闲分区链)或者[空闲分区表](#空闲分区表)，找到大小能满足要求的第一空闲分区。

##### 缺点

每次都选最小的分区进行分配，会留下越来越多的、很小的、很难利用的内存块。这种方法会产生很多很多的[外部碎片](#外部碎片)

* * *

#### 最坏时应算法(Worst Fit)

又称为最大最大适应算法

##### 算法思想

为了解决最佳适应算法的问题——留下太多难以利用的小碎片，可以在每次分配的时候，优先选择最大的连续空闲区，这样分配后剩余的空闲区就不会太小，更方便使用

##### 如何实现

空闲分区按容量递减的次序链接。每次分配内存时顺序查找[空闲分区链](#空闲分区链)或者[空闲分区表](#空闲分区表)，找到大小满足要求的第一个空闲分区，需要对空闲分区链进行重新排序

##### 缺点

由于每次都选择最大分区进行分配，会使大分区变小，如果有一个大进程到达，就没有分区可用了

* * *

#### 邻近适应算法(Next Fit)

##### 算法思想

首次适应算法每次都从链头开始查找的。这可能导致低地址部分出现很多很小的空闲分区，而每次分配查找的时候，都要经过这些分区，因此也增加了查找的开销。如果每次都从上次查找结束的位置开始检索，就能解决上述问题。

##### 如何实现

空闲分区以地址递增的顺序排列（可排成一个循环链表）。每次分配内存时从**上次查找结束的位置开始**查找[空闲分区链](#空闲分区链)或者[空闲分区表](#空闲分区表)，找到大小能满足要求的第一个空闲分区，不需要对链表进行重新排列。

##### 缺点

因为每次都是从上一次分配的位置开始查找，可能导致大分区被划分为小分区，最后会无大分区可用

#### 总结

* * *

## 分页管理

### 连续分配的缺点

1. 固定分区分配：缺乏灵活性，如果进程占不满一个分区，会产生很多[内部碎片](#内部碎片)，内存利用率很低。
2. 动态分区分配：会留下难以利用的很小的外部碎片，虽然可以利用**紧凑技术**来解决，但是**紧凑**的时间代价很高

### 把固定分区分配改造为非连续分配版本

#### 问题

假设进程A的大小为23MB，但是每个分区大小只有10MB，如果进程只能占一个分区，显然放不下。

#### 解决思路

如果允许进程占用多个分区，那么可以把进程拆分成10MB+10MB+3MB三个部分再把这三个部分放入分区中（分区不要求连续）

**显然，如果把每个分区大小设置得更小，内部碎片会更小，内存利用率会更高**

### 分页管理的基本概念

#### 概念

1. 将内存空间分为一个个大小相等的分区，每个分区就是一个“页框”，或者称为“页帧”、“内存块”、“物理块”。每个页框有一个编号，即“页框号”、从0开始。
2. 将用户进程的地址空间也分为与页框大小相等的一个个区域，称为“页”或者“页面”。每个页面也会有一个编号，即“页号”。
3. 页是将进程分为和页帧同样的大小后的地址空间，是以进程为参照物的。
4. 页帧是将内存空间氛围大小相等的分区，是以内存空间为参照物的。
5. 进程的最后一个页面可能没有一个页框那么大。因此，页框不能太大，否则会产生过大的内部碎片。
6. 操作系统以页框为单位，为各个进程分配内存空间。进程的每个页面分别放入一个页框当中。也就是说，进程的页面与内存的页框有一一对应的关系。
7. 各个页面不必连续存放，也不必按先后顺序来，可以放到不相邻的各个页框中。
8. 页框是实际的物理地址，页只是一组数据块，可以存放到任何页框当中

#### 逻辑地址结构

分页存储管理的逻辑地址结构包含两个部分：

1. 第一部分为页号
2. 第二部分为页内偏移量

如果K位来表示页内偏移量，则表示该系统的页面大小为2^K
如果M位来表示页号，则表示该系统进程最多允许2^M个页面

### 页表

为了能知道进程的每个页面在内存中存放的位置，操作系统要为每个进程建立一张页表

1. 一个进程对应一张页表
2. 进程的每一页对应一个页表项
3. 每个页表项由**页号**和**块号**组成
   块号指的是实际存放的内存块的编号（虚拟的）用来抽象的描述内存的起始地址的。
   M号内存块的起始地址就是M × (内存块大小）
4. 页表记录**进程页面和实际存放的内存块之间的对应关系**

页号  = 逻辑地址/页面大小； 页内偏移量 = 逻辑地址%页面大小
或者可以根据逻辑地址结构计算，  逻辑地址 = 【页号P, 页内偏移量W】

Eg：假设某系统物理内存大小为4Gb，页面大小为4Kb，则每个页表项至少应该为多少字节？

4Gb = 2^32B, 4KB = 2^12B

因此4GB的内存会被分为2^32/2^12=2^20个内存块，因此内存块号的范围应该是0~2^20 - 1
因此至少需要20个2进制位才能表示那么多内存块号，因此在页表项中表示内存块号至少需要3个字节

各页表项会按顺序连续地存放在内存中
如果该页表在内存中存放的起始地址为X，则M号对应的页表项一定是存放在内存地址为X +3×M
只需要知道**页表存放的起始地址**和**页表项**长度，即可找到各个页号对应的页表项存放的位置

页号不必要用专门的长度表示出来，知道页表在内存中存放的起始地址X后，因为每个内存块号的大小是固定的，所以3×M就是M页基于起始地址的偏移量，所以 3×M + 起始地址 就可以知道M号对应的页表项存放的位置了

### 基本地址变换机构

- 重点理解、记忆基本地址变换机构（用于实现逻辑地址到物理地址转换的一组硬件机构）的原理和流程。

基本地址变换机构可以借助进程的页表将逻辑地址转换为物理地址。
通常会在系统中设置一个页表寄存器（PTR），存放页表在内存中的起始地址F和页表长度M。
进程未执行时，页表的始址和页表长度放在[进程控制块（PCB）](#进程)中，当进程被调度时，操作系统内核会把它们放到页表寄存器中。

1. 根据逻辑地址算出页号，页内偏移量
2. 判断页号是否越界
3. 查询页表，找到页号对应的页表项，确定页面存放的内存块号
4. 用内存块号和页内偏移量得到物理地址
5. 访问内存单元

注意页面大小是2的整数幂
设页面大小为L，逻辑地址A到物理地址E的变换过程如下：

1. 计算页号P和页内偏移量W
   （如果用十进制手算，P=A/L，W=A%L；但是在计算机实际运行时，逻辑地址结构是固定不变的，因此计算机硬件可以更快地得到二进制表示的页号，页内偏移量）
2. 比较页号P和页表长度M，若P≥M，则产生越界中断，否则继续执行。
   （注意：页号是从0开始的，而页表长度至少是1，因此P=M时也会越界）
3. 页表中页号P对应的页表项地址=**页表项起始地址F+页号P\*页表项长度**，取出该页表项内容b，即为内存块号。

注意区分页表项长度，页表长度，页面大小的区别。

- 页表长度
  指的是这个页表总共有几个页表项，即总共有几个页。
- 页表项长度
  指的是每个页表占多大的存储空间；
- 页面大小
  指的是一个页面占多大的存储空间

例：若页面大小L为1K字节，页号2对应点内存块号b=8，将逻辑地址A=2500转换为物理地址E。
页面大小为1K字节，1K = 2^10，所以页内偏移量占10位。

1. 计算页号、页内偏移量
   页号P=A/L=2500/1024 = 2，页内偏移量W=A%L=2500%1024 = 452

### 对页表项的进一步讨论

**前情提要：需要把页表放入内存中才能读取**

Eg：假设某系统物理内存大小为4GB，页面大小为4KB的内存总共会被分成2^32/2^12=2^20个内存块，因此内存块号的范围应该是0~2^20-1
因此至少需要20个二进制位才能表示这么多的内存块号，因此页表项的长度至少要3个字节才够
（每个字节8个二进制位，3个字节共24个二进制位）

1. 各页表项会按顺序连续地存放在内存中
2. 如果该页表在内存的起始地址为X，则M号页对应的页表项是存放在内存地址为X+3×M

一个页面大小为4Kb，则每个页面可以存放4096/3 = 1365个页表项，但是这个页框会剩余4096%3=1B页内碎片
因此，1365号页表项存放的地址为X +3 × 1365 + 1，其中1为一字节的误差

如果每个页表占4个字节，则每个页框刚好刚好可存放1024个页表项
1024号页表项虽然是存放在下一个页框中，但是它的地址依然可以用 X +1024 × 4 得出

#### 总结

1. 理论上，页表项长度为3B即可表示内存块号的范围，但是，为了方便页表的查询，常常会让一个页表占更多的字节，使得每个页面恰好可以装得下整数个页表项。
2. 进程页表通常是装在连续的内存块中

### 具有快表的地址变换机构

#### 局部性原理

```cpp
int i = 0;
int a[100];
while (i < 100) {
  a[i] = i;
  i++;
}
```

1. 程序在编译之后，会形成与他对等的机器指令，会存放在某一个内存块①中
2. 程序定义的变量i，数组会放入另一个内存块②中

**时间局部性**：如果在程序中执行某条指令，那么不久后这条指令很可能再被执行；如果某个数据被访问过，不久之后该数据很可能再次被访问。（因为程序中存在大量的循换）
**空间局部性**：一旦程序访问了某个储存单元，在不久之后，其附近的存储单元也很有可能被访问。（因为很多数据在内存中都是连续存放的）

使用[基本地址变换机构](#基本地址变换机构)访问一个逻辑地址，都需要查询内存中的页表。由于局部性原理，可能连续很多次查到的都是同一个页表项。可以利用这个特性，减少对页表辅访问次数。

#### 快表(TLB)

快表，又称为联想寄存器，是一种访问速度比内存快很多的告诉缓冲存储器，用来存放当前访问的若干页表项，以加速地址变换的过程。与此对应，内存中的页表常称为慢表。

#### 引入快表后，地址的变换过程

1. CPU给出逻辑地址，由某个硬件得到页号，页内偏移量，将页号与快表中的所有页号进行比较
2. 如果找到匹配的页号，说明要访问的页表项在块表中有副本，则直接从中取出该页对应的内存块号，再将内存块与页内偏移量拼接形成物理地址，最后，访问该物理地址的内存单元。因此，若快表命中，则访问某个逻辑地址仅需一次访存即可。
3. 如果没有找到匹配的页号，则需要访问内存中的页表，找到对应的页表项，得到页面存放的内存块号，再将内存块号与页内偏移量拼接形成物理地址，最后，访问该物理地址对应的内存单元。因此，若快表未命中，则访问某个逻辑地址需要两次访存。（**注意：在找到页表项后，应同时将其存入快表**，以便后面可能的再次访问。但若快表已满，则必须按照一定的算法对旧的页表项进行替换）

PS： 关于第三点的理解，需要先去页表中找到对应的页表项，再根据页表项去内存中访问特定的内存块，所以是两次访问，页表和内存块是两个东西...

### 两级页表

#### 单级页表的问题

问题一：页表必须连续存放，因此当页表很大的时候，需要占用很多个连续的页框
问题二：没有必要让整个页表常驻内存，因为进程在一段时间内可能只需要访问某几个特定的页面

可以很长的页表进行扥组，使每个内存块刚好可以放入一个分组
另外，要为离散分配的页表再建立一张页表，称为页目录表，或称外层页表，或称为顶层页表

#### 两级页表的原理

在页表中有：一级页号和二级页号和页内偏移量
32位的逻辑地址空间，页表项大小为4B，页面大小为4KB，则页内地址占12位

$$
2^2 \\times 2^{10} = 2^{12}
$$

进程最多有2的20次方个页面，用20位二进制刚好可以表示0~2的20次方-1个页号。
$$
\\frac {2^{32}} {2^{12}} = 2^{20}
$$

每个页面可存放4K/4=1K=2^10=1024个页表项。

每个小页表的大小都是4KB，因为每个页表项大小为4B，并且一个小页表有1024个页表项，所以一个小页表的大小为4KB

因为每个页面的大小为4KB，所以可以把页表放入页框内。

所以顶级页表中存了1024个小页表，并且每个

#### 如何实现地址变换

①按照地址结构将逻辑地址拆分为三部分
②从PCB中独处页目录表起始地址，再根据以及也好查找页目录表，找到下一级页表在内存中的存放位置
③根据二级页号查表，找到最终想访问的内存块号
④结合页内偏移量得到物理地址

#### 两级页表需要注意的几个细节

1. 若采用多级页表机制，则各级页表的大小不能超过一个页面
   例：某系统按字节编制，采用40位逻辑地址，页面大小为4KB，页表项大小为4B，假设采用纯页式存储，则要采用（）级页表？页内偏移量为（）位？
   页面大小= 4KB = 2^12B，按字节编址，因此页内偏移量为12位
   页号= 40-12 =28位
   页面大小=2^12B，页表项大小=4B，则每个页面可存放2^12/4 = 2^10个页表项
   因此各级页表最多饱和2^10个页表项，所以至少为3级
   按8,10,10分级 上面的28位

2. 两级页表的访存次数分析（没有TLB）
   第一次访存：访问内存中的页目录表
   第二次访存：访问内存中的二级页表
   第三次访存：访问目标内存单元

* * *

## 分段管理

### 什么是分段

进程的地址空间：按照程序自身的逻辑关系划分为若干个段，每个段都有一个段名（在低级语言中，程序员使用段名来编程）草

### 什么是段表

为了保证程序运行，就必须能从物理地址找到各个逻辑段的存放位置。为此，需要为每个进程建立一张映射表，简称“段表”。

1. 每个段对应一个段表项，其中记录了该段在内存中的起始位置（又称为“基址”）和段的长度
2. 各个**段表项**的长度是相同的。段表项在内存中所占的空间是相同的。若段表的存放的起始地址为M，则K号地址对应的段表项存放的地址为M+K\*段表项大小

### 如何实现地址变换

1. 由逻辑地址得到段号，段内地址。
2. 段号与段表寄存器的段长度比较，是否越界。
3. 由段表始址、段号找到对应的段表项
4. 根据段表中记录的段长，检查段内地址是否越界
5. 由段表中的“基址+段内地址”得到最终的物理地址
6. 访问目标单元

* * *

## 段页式管理

### 分页管理

#### 优点

内存空间利用率高，不会产生外部碎片，只会有少量的内部碎片。

#### 缺点

不方便按照逻辑模块实现信息的共享和保护

### 分段管理

#### 优点

很方便按照逻辑模块实现信息的共享和保护

#### 缺点

如果段长过大，为其分配很大的连续空间很可能不方便，另外，段式管理会产生外部碎片

### 分段+分页=段页式

将进程按照逻辑模块进行分段，再对各段分页，再将内存空间分为大小相同的内存块。

1. 段号的位数决定每个进程可以分为几个段
2. 页号的位数决定了每个段最大有多少页
3. 页内偏移量决定了页面大小、内存块的大小是多少

* * *

# 虚拟内存的基本概念

## 传统存储管理方式的特征、缺点

连续分配

1. 单一连续分配
2. 固定分区分配
3. 动态分区分配

非连续分配

1. 基本分页储存管理
2. 基本分段储存管理
3. 基本段页式储存管理

很多暂时用不到的数据，也会长期占用内存，导致内存利用率不高。

一次性：作业必须一次性全部装入内存才能开始运行。
①作业量过大时，不能全部装入内存，导致大作业无法完成。
②当大量作业要求运行时，由于内存无法容纳所有作业，因此只有少量作业能运行，导致多道程序并发度下降。

驻留性：一旦作业被装入内存，就会一直驻留在内存中，直到作业运行结束。事实上，在一个时间段内，只需要访问作业的一小部分数据即可正常运行，这就导致了内存中会驻留大量的，暂时用不到的数据，浪费了宝贵的内存资源。

* * *

### 高速缓存技术

将近期会频繁使用的数据放到更高速的存储器中，暂时用不到的数据放在更低速的存储器中。

* * *

## 虚拟内存的定义和特征

### 定义

1. 基于局部性原理，在程序装入时，可以将程序中很快会用到的部分装入内存，暂时用不到的部分留在外村，就可以让程序开始执行。
2. 在程序执行的过程中，当所访问的信息不再内存时，由操作系统负责将所需的信息从外存调入内存，然后继续执行程序。
3. 若内存空间不够，由操作系统负责将内存中暂时用不到的信息换出到外存
4. 在操作系统的管理下，在用户看来似乎有一个比实际大得多的内存，这就是虚拟内存

- 虚拟内存的最大容量是由计算机地址结构决定的
- 虚拟内存的实际容量 = min（内存和外存容量之和， 寻址范围）

### 特性

1. 多次性：
   无需在作业运行时一次性全部装入内存，而是允许被多次调入内存
2. 对换性：
   在作业运行时无需一直常驻内存，而是允许在作业运行的过程中，将作业换入换出
3. 虚拟性：
   从逻辑上扩充了内存的容量，使用户看到的内存容量，远大于实际的容量

* * *

## 如何实现虚拟内存技术

虚拟内存技术，允许一个作业分多次调入内存。如果使用连续分配方式，会不方便实现。因此，虚拟内存的实现需要建立在离散分配的内存管理方式基础上。

在程序执行的过程中，当所访问的信息不在内存时，由操作系统将所需信息从外存调入内存，然后继续执行程序。

若内存空间不够，由操作系统负责将内存中暂时用不到的信息换出到外存。

### 实现

1. 请求分页存储管理
2. 请求分段存储管理
3. 请求段页式存储管理

* * *

## 请求分页处理方式

### 请求分页储存管理与基本分页管理的主要区别

1. 在程序执行的过程中，当所访问的信息不在内存时，由操作系统负责将所需信息从外存调入内存，然后继续执行程序
2. 若内存空间不够，由操作系统负责将内存中暂时用不到的信息换出到外存

### 页表机制

请求分页的页表：

1. 内存块号
2. 状态位
   用于记录是否已调入内存
3. 访问字段
   可记录最近被访问过几次，或记录上次访问的之间，供被置换算法选择换出页面时参考
4. 修改位
   页面调入内存后是否被修改过
5. 外存地址
   页面在外存中存放的位置

### 缺页中断机构

假设此时要访问的逻辑地址=（页号，页内偏移量）=（0,1024）

在请求分页系统中，每当**要访问的页面不在内存**时，便产生一个**缺页中断**，然后由操作系统的**缺页中断处理程序处理中断**

此时**缺页中断的进程阻塞**，放入阻塞队列，调页**完成后再将其唤醒**，放回就绪队列。

如果内存中有空闲块，则为进程分配一个空闲块，将所缺页面装入该块，并修改页表中相应的页表项。

如果内存中没有空闲块，则由页面置换算法选择一个页面淘汰，若该页面在内存期间被修改过，则要将其写回外存，把外存的旧数据覆盖掉。未修改的页面不用写回外存

缺页中断是因为当前执行的指令想要访问的目标页面未调入内存而产生的，因此属于内中断

一条指令在执行的过程中，可能会产生多次缺页中断。

### 地址变换机构

1. 请求调页
2. 页面置换（在没有空闲内存块的时候进行）
3. 需要修改请求页表中新增的表项

- 快表中存在的页面一定是在内存中的。若某个页面被换出外存，则块表中的相应表项也要删除，否则可能访问错误的页面。
- 找到对应页表项后，若对应页面未调入内存，则产生缺页中断，之后由操作系统的缺页中断处理程序进行处理。

* * *

## 页面置换算法

### 最佳置换算法（OPT）

#### 概念

最佳置换算法（OPT，Optimal）：每次选择的淘汰的页面将是**以后永不使用**，或者**在最长时间内不再被访问的页面**，这样可以保证最低的缺页率。

#### 实现

需要知道接下来需要访问哪个页面，只是一个理想算法，在实际中无法实现。

* * *

### 先进先出置换算法（FIFO）

#### 概念

每次选择淘汰的页面是最早进入内存的页面

#### 实现

把调入内存的页面根据调入的先后顺序排成一个队列，需要换页面时将对头页面换出即可。

* * *

### 最近最久未使用置换算法（LRU）

#### 概念

每次淘汰的页面是最近最久未使用的页面

#### 实现方法

赋予每个页面对应的页表项中，用访问字段记录该页面自上次被访问以来所经历的时间t
当需要淘汰一个页面时，选择现有页面中t值最大的，即最近最久未使用的页面

* * *

### 时钟置换算法（CLOCK）

#### 实现方法

为每个页面设置一个访问位，再将内存中的页面都通过链接指针链接成一个循环队列。当某页被访问时，其访问位置为1,。当需要淘汰一个页面时，只需检查页的访问位。

1. 如果是0，将其换出。
2. 1. 如果是1，将其置为0，暂不换出，继续检查下一个页面，若第一轮扫描中所有页面都是1，则将这些页面的访问位依次置换为0。
   2. 第二轮扫描，一定会有一个为0的页面。

只有发生缺页中断的时候，指针才会移动，简单来说，就是在状态为由0变为1，并且页也发生变换的时候才会移动。

### 改进型的时钟置换算法

简单的时钟置换算法仅考虑到一个页面最近是否被访问过。事实上，如果被淘汰的页面没有被修改过，就不需要进行I/O操作写回外存。**只有被淘汰的页面被修改过，才需要写回外存**。

因此，除了考虑一个页面最近有没有被访问过之外，操作系统还应考虑页面有没有被修改过。在其他条件都相同时，应优先淘汰没有修改过的页面，避免I/O操作。

修改位=0，表示页面没有被修改过；修改位=1，表示页面被修改过。

为方便讨论，用（访问位，修改位）的形式表示各页面的状态。如（1,1）表示一个页面近期被访问过，也被修改过。

#### 算法规则

1. 将所有可能被置换的页面排成一个循环队列
2. 从当前位置开始扫描找到第一个（0,0）的页帧用于替换。本轮扫描不修改任何标志位
3. 第一轮扫描失败，则重新扫描，查找第一个（0,1）的页帧用于替换。本轮扫描将所有扫描过的页帧访问位设为0
4. 第二轮扫描失败，则重新扫描，查找第一个（0,0）的页帧用于替换。本轮扫描不修改任何标志位
5. 第三轮扫描失败，则重新扫描，查找第一个（0,1）的页帧用于替换。

由于第二轮已将所有的访问位设为0，因此经过第三轮，第四轮扫描，一定会有一个帧被选中。
改进型的时钟算法最多进行四轮扫描

- 第一优先级：最近没有被访问，且没有被修改（0,0）
- 第二优先级：最近没有被访问，但是被修改过（0,1）
- 第三优先级：最近有被访问过，但没有被修改（1,0）
- 第四优先级：最近有被访问过，且有被修改过（1,1）

* * *

# 文件系统

## 文件系统基础

### 文件的属性

1. 文件名
   由创建文件的用户决定文件名，主要是为了方便用户找到文件，同一目录下不允许重名文件
2. 标识符
   一个系统内的各文件标识符唯一，对用户来说毫无可读性
3. 类型
   指明文件的类型
4. 位置
   文件存放的路径、在外存中的地址（对用户不可见）
5. 文件大小
6. 创建时间
7. 上次修改时间
8. 文件所有者信息
9. 文件保护信息

## 文件的逻辑结构

### 无结构文件

由一系列二进制或者字符流组成。如：windows系统中的txt文件

### 有结构文件

由一组相似的记录组成，又称“记录式文件”。每条记录又由若干个数据项组成。如数据库表文件。一般来说，每条记录有一个数据项可作为**关键字**。根据各条记录的长度是否相等，又可分为**定长记录**和**可变长记录**。

1. 定长记录
2. 可变长记录

### 顺序文件

文件中的记录一个接一个地顺序排列，记录可以是**定长**的或者**可变长**的。各个记录在屋里地之上可以**顺序储存**或者**链式储存**

#### 链式存储

无论是定长/可变长记录，都无法实现随机存取，每次只能从第一个纪录开始依次往后查找

#### 顺序存储

##### 可变长记录

无法实现随机存取。每次只能从第一个记录开始依次往后查找。

##### 定长记录

1. 可以实现随机存取。记录长度为L，则第i个记录存放的相对位置是i\*L
2. 若采用串结构，无法快速找到某关键字对应的记录
3. 若采用顺序结构，可以快速找到某关键字对应的记录

## 文件目录

### 文件控制块

根目录下的每一个文件都对应文件目录表中的一条记录

当我们双击“文件夹”后，操作系统会在这个目录表找到关键字“文件夹”对应的目录项，然后从外存中将“文件夹”目录的信息读入内存，于是，“文件夹”中的内容就可以显示出来了。

### 目录结构

#### 单级目录结构

早期操作系统并不支持多及目录，整个系统中只建立一张目录表，每个文件占一个目录项

单级目录实现“按名存取”，但不允许文件重名

在创建一个文件后，首先检查目录表中有没有重名文件，确定不重名后才能允许建立文件，并将新文件对应的目录项插入目录表中

#### 两级目录结构

分为主文件目录和用户文件目录

- 主文件目录（MFD，Master File Directory）
- 用户文件目录（UFD，User File Directory）

#### 多级目录结构

又称为树形目录结构

不同目录下的文件可以重名，各级目录之间用“/”隔开，从根目录出发的路径称为**绝对路径**

很多时候，用户会连续访问同一目录下的多个文件，因此可以设置一个**当前目录**，从当前目录出发的路径就叫**相对路径**，如：“./cpp/1.cpp”

树形目录结构不便于实现文件共享

#### 无环图目录结构

在树形目录结构的基础上，增加一些指向同一节点的有向边，使整个目录称为一个有向无环图。可以更方便地实现多个用户间的文件共享。

可以用不同的文件名指向同一个文件，甚至可以指向同一个目录（共享同一目录下的所有内容）

需要为每个共享节点设置一个共享计数器，用于记录有多少个地方在共享该节点。用户提出删除节点的请求时，这是删除该用户的FCB、并使共享计数器减一，并不会删除共享节点。

注意：共享文件不同于复制文件。在共享文件中，由于各用户指向的是同一个文件，所以只要其中一个用户更新了文件内容，那么所有用户都可以看到文件数据的变化。

## 文件的物理结构

### 文件块，磁盘块

类似于内存分页，磁盘中的存储单元会被分为一个个**块**。很多操作系统中，磁盘块的大小和内存块、页面大小相同。

在内存管理中，进程的逻辑地址空间被分为一个个页面

同样的，在外存管理中，为了方便对文件数据的管理，文件的逻辑地址空间也被分为一个一个的文件块。

于是文件的逻辑地址也可以表示为（逻辑块号，块内地址）的形式。

### 连续分配

#### 概念

连续分配方式要求每个文件在磁盘上占有一组连续的块

物理块号=起始块号+逻辑块号

可以直接读逻辑块号对应的物理块号，因此连续分配支持顺序访问和直接访问

读取某个磁盘块时，需要移动刺头。访问的两个磁盘相隔越远，移动磁头所需时间就越长。所以连续分配读取更快

#### 优点

连续分配的文件在顺序读写的时候速度最快

#### 缺点

1. 物理上采用连续分配的文件不方便拓展
2. 会产生难以利用的磁盘碎片，可以用紧凑的方式解决，但是会花费很大的时间代价。

### 链接分配

链接分配采取离散分配的思想，可以为文件分配离散的磁盘块。分为**隐式链接**和**显式链接**

#### 隐式链接

1. 目录中记录了文件存放的起始块号和结束块号
2. 除了文件最后一个磁盘块，每个磁盘块都会保存指向下一个磁盘块的指针，这些指针对用户来说是透明的

##### 缺点

采用链式分配，只支持顺序访问，不支持随机访问，查找效率低。

##### 优点

很方便文件的拓展，不会产生碎片问题，外存利用率很高

#### 显式链接

把用于链接文件各物理块的指针显式地存放在一张表中。即 文件分配表（FAT，File Allocation Table）

##### 逻辑地址到物理地址的转换

从目录项中找到起始块号，若i>0，则查询内存中的文件分配表FAT，往后找到i号逻辑块对应的物理块号。逻辑块号转换成物理块号的过程不需要读磁盘操作。

#### 优点

很方便文件扩展，不会有碎片问题，外存利用率高，并且支持随机访问。相比于隐式链接来说，地址转换时不需要访问磁盘，因此文件访问效率更高

#### 缺点

文件分配表需要占用一定的存储空间

### 索引分配

索引分配允许文件离散地分配在各个磁盘块中，系统会为每个文件建立一张索引表，索引表中记录了文件的各个逻辑块对应的物理块。索引表存放的磁盘块称为**索引块**。文件数据存放的磁盘块称为**数据块** 。

